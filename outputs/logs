2025-05-19 11:35:15,455 Save logging info to ./outputs/logs
2025-05-19 11:35:15,455 config file: {'PerfRequirement': {'TTFT': 3000, 'TPOT': 100}, 'OutputHWUsage': True, 'Model': {'model_name': 'DeepSeek-R1-Distill-Qwen-7B', 'model_path': '/root/.cache/modelscope/hub/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B', 'tokenizer_path': '/root/.cache/modelscope/hub/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B'}, 'Dataset': {'use_random': False, 'data_name': 'ceval_gen', 'data_path': '/data/jason2.li/gitlab/llm_eval_toolkit/datasets/ceval'}, 'Device': 'gcu', 'DeployParam': {'batch_size': 1, 'max_batch_size': 10, 'tensor_parallel_size': 1, 'pipeline_parallel_size': 1, 'expert_parallel_size': 1, 'gpu_memory_utilization': 0.78, 'trust_remote_code': True, 'block_size': 64, 'enable_chunked_prefill': True, 'enable_prefix_caching': False, 'disable_async_output_proc': True, 'enforce_eager': False, 'distributed_executor_backend': None, 'max_num_seqs': 256, 'enable_thinking': True}, 'ModelKwargs': {'dtype': 'bfloat16', 'max_model_len': 8192, 'quantization': None}, 'SamplingParams': {'num_seqs': 1, 'max_tokens': 240, 'output_len': 240, 'temperature': 0, 'top_p': 1, 'top_k': 1, 'ignore_eos': True, 'keep_special_tokens': True, 'strict_in_out_len': True}, 'Logging': {'save_dir': './outputs/logs'}, 'MetricType': 'Perf', 'EvalTool': 'BenchmarkTest', 'InferType': 'offline', 'Acc': {'OpenCompass': {'datasets': 'ceval_gen'}, 'BenchmarkTest': {'disable-log-stats': True}, 'lm_eval': {'model': 'local-completions', 'tasks': 'ceval-valid', 'num_fewshot': 0, 'seed': 0, 'verbosity': 'DEBUG', 'log_samples': True, 'show_config': True, 'apply_chat_template': True, 'base_url': 'http://0.0.0.0:8000/v1/completions', 'num_concurrent': 1}, 'EvalScope': {'url': 'http://0.0.0.0:8000/v1/completions', 'eval_type': 'service', 'datasets': 'ceval', 'limit': 10}}, 'Perf': {'BenchmarkServing': {'input_len': 512, 'dataset_name': 'random', 'dataset_path': None, 'request_rate': 'inf', 'host': '0.0.0.0', 'port': 8000, 'endpoint': '/v1/completions', 'max_concurrency': None}, 'EvalScope': {'max_prompt_length': 5120, 'min_prompt_length': 128, 'url': 'http://0.0.0.0:8000/v1/completions', 'api': 'openai', 'dataset': 'random', 'parallel': 1, 'number': 15, 'read_timeout': 600, 'connect_timeout': 600, 'stream': True}, 'BenchmarkTest': {'input_len': 512}}, 'PerfTunning': {'BenchmarkTest': {'max_num_prompts': 100, 'min_num_prompts': 1, 'grid_num_prompts': 10}, 'BenchMarkServing': {'min_request_rate': 0.1, 'max_request_rate': 10, 'grid_request_rate': 1, 'min_num_prompts': 1, 'max_num_prompts': 100, 'grid_num_prompts': 10}}}
2025-05-19 11:35:15,455 MetricType: Perf
2025-05-19 11:35:15,455 EvalTool: BenchmarkTest
2025-05-19 11:35:15,456 InferType: offline
2025-05-19 11:35:15,571 GCU info: {'name': b'Enflame S60', 'total_memory(MB)': 49120.0, 'utilization_rates(%)': {'max': 0, 'ave': 0.0}, 'power_usage(W)': {'max': 98.0, 'ave': 98.0}}
2025-05-19 11:35:15,571 Finished running Perf using BenchmarkTest
2025-05-19 11:36:07,711 Save logging info to ./outputs/logs
2025-05-19 11:36:07,711 config file: {'PerfRequirement': {'TTFT': 3000, 'TPOT': 100}, 'OutputHWUsage': True, 'Model': {'model_name': 'DeepSeek-R1-Distill-Qwen-7B', 'model_path': '/root/.cache/modelscope/hub/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B', 'tokenizer_path': '/root/.cache/modelscope/hub/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B'}, 'Dataset': {'use_random': False, 'data_name': 'ceval_gen', 'data_path': '/data/jason2.li/gitlab/llm_eval_toolkit/datasets/ceval'}, 'Device': 'gcu', 'DeployParam': {'batch_size': 1, 'max_batch_size': 10, 'tensor_parallel_size': 1, 'pipeline_parallel_size': 1, 'expert_parallel_size': 1, 'gpu_memory_utilization': 0.78, 'trust_remote_code': True, 'block_size': 64, 'enable_chunked_prefill': True, 'enable_prefix_caching': False, 'disable_async_output_proc': True, 'enforce_eager': False, 'distributed_executor_backend': None, 'max_num_seqs': 256, 'enable_thinking': True}, 'ModelKwargs': {'dtype': 'bfloat16', 'max_model_len': 8192, 'quantization': None}, 'SamplingParams': {'num_seqs': 1, 'max_tokens': 240, 'output_len': 240, 'temperature': 0, 'top_p': 1, 'top_k': 1, 'ignore_eos': True, 'keep_special_tokens': True, 'strict_in_out_len': True}, 'Logging': {'save_dir': './outputs/logs'}, 'MetricType': 'Perf', 'EvalTool': 'BenchmarkTest', 'InferType': 'offline', 'Acc': {'OpenCompass': {'datasets': 'ceval_gen'}, 'BenchmarkTest': {'disable-log-stats': True}, 'lm_eval': {'model': 'local-completions', 'tasks': 'ceval-valid', 'num_fewshot': 0, 'seed': 0, 'verbosity': 'DEBUG', 'log_samples': True, 'show_config': True, 'apply_chat_template': True, 'base_url': 'http://0.0.0.0:8000/v1/completions', 'num_concurrent': 1}, 'EvalScope': {'url': 'http://0.0.0.0:8000/v1/completions', 'eval_type': 'service', 'datasets': 'ceval', 'limit': 10}}, 'Perf': {'BenchmarkServing': {'input_len': 512, 'dataset_name': 'random', 'dataset_path': None, 'request_rate': 'inf', 'host': '0.0.0.0', 'port': 8000, 'endpoint': '/v1/completions', 'max_concurrency': None}, 'EvalScope': {'max_prompt_length': 5120, 'min_prompt_length': 128, 'url': 'http://0.0.0.0:8000/v1/completions', 'api': 'openai', 'dataset': 'random', 'parallel': 1, 'number': 15, 'read_timeout': 600, 'connect_timeout': 600, 'stream': True}, 'BenchmarkTest': {'input_len': 512}}, 'PerfTunning': {'BenchmarkTest': {'max_num_prompts': 100, 'min_num_prompts': 1, 'grid_num_prompts': 10}, 'BenchMarkServing': {'min_request_rate': 0.1, 'max_request_rate': 10, 'grid_request_rate': 1, 'min_num_prompts': 1, 'max_num_prompts': 100, 'grid_num_prompts': 10}}}
2025-05-19 11:36:07,711 MetricType: Perf
2025-05-19 11:36:07,711 EvalTool: BenchmarkTest
2025-05-19 11:36:07,711 InferType: offline
2025-05-19 11:36:07,827 GCU info: {'name': b'Enflame S60', 'total_memory(MB)': 49120.0, 'utilization_rates(%)': {'max': 0, 'ave': 0.0}, 'power_usage(W)': {'max': 98.0, 'ave': 98.0}}
2025-05-19 11:36:07,828 Finished running Perf using BenchmarkTest
2025-05-19 11:42:34,574 Save logging info to ./outputs/logs
2025-05-19 11:42:34,574 config file: {'PerfRequirement': {'TTFT': 3000, 'TPOT': 100}, 'OutputHWUsage': True, 'Model': {'model_name': 'DeepSeek-R1-Distill-Qwen-7B', 'model_path': '/root/.cache/modelscope/hub/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B', 'tokenizer_path': '/root/.cache/modelscope/hub/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B'}, 'Dataset': {'use_random': False, 'data_name': 'ceval_gen', 'data_path': '/data/jason2.li/gitlab/llm_eval_toolkit/datasets/ceval'}, 'Device': 'gcu', 'DeployParam': {'batch_size': 1, 'max_batch_size': 10, 'tensor_parallel_size': 1, 'pipeline_parallel_size': 1, 'expert_parallel_size': 1, 'gpu_memory_utilization': 0.78, 'trust_remote_code': True, 'block_size': 64, 'enable_chunked_prefill': True, 'enable_prefix_caching': False, 'disable_async_output_proc': True, 'enforce_eager': False, 'distributed_executor_backend': None, 'max_num_seqs': 256, 'enable_thinking': True}, 'ModelKwargs': {'dtype': 'bfloat16', 'max_model_len': 8192, 'quantization': None}, 'SamplingParams': {'num_seqs': 1, 'max_tokens': 240, 'output_len': 240, 'temperature': 0, 'top_p': 1, 'top_k': 1, 'ignore_eos': True, 'keep_special_tokens': True, 'strict_in_out_len': True}, 'Logging': {'save_dir': './outputs/logs'}, 'MetricType': 'Perf', 'EvalTool': 'BenchmarkTest', 'InferType': 'offline', 'Acc': {'OpenCompass': {'datasets': 'ceval_gen'}, 'BenchmarkTest': {'disable-log-stats': True}, 'lm_eval': {'model': 'local-completions', 'tasks': 'ceval-valid', 'num_fewshot': 0, 'seed': 0, 'verbosity': 'DEBUG', 'log_samples': True, 'show_config': True, 'apply_chat_template': True, 'base_url': 'http://0.0.0.0:8000/v1/completions', 'num_concurrent': 1}, 'EvalScope': {'url': 'http://0.0.0.0:8000/v1/completions', 'eval_type': 'service', 'datasets': 'ceval', 'limit': 10}}, 'Perf': {'BenchmarkServing': {'input_len': 512, 'dataset_name': 'random', 'dataset_path': None, 'request_rate': 'inf', 'host': '0.0.0.0', 'port': 8000, 'endpoint': '/v1/completions', 'max_concurrency': None}, 'EvalScope': {'max_prompt_length': 5120, 'min_prompt_length': 128, 'url': 'http://0.0.0.0:8000/v1/completions', 'api': 'openai', 'dataset': 'random', 'parallel': 1, 'number': 15, 'read_timeout': 600, 'connect_timeout': 600, 'stream': True}, 'BenchmarkTest': {'input_len': 512}}, 'PerfTunning': {'BenchmarkTest': {'max_num_prompts': 100, 'min_num_prompts': 1, 'grid_num_prompts': 10}, 'BenchMarkServing': {'min_request_rate': 0.1, 'max_request_rate': 10, 'grid_request_rate': 1, 'min_num_prompts': 1, 'max_num_prompts': 100, 'grid_num_prompts': 10}}}
2025-05-19 11:42:34,574 MetricType: Perf
2025-05-19 11:42:34,574 EvalTool: BenchmarkTest
2025-05-19 11:42:34,574 InferType: offline
2025-05-19 11:42:34,703 GCU info: {'name': b'Enflame S60', 'total_memory(MB)': 49120.0, 'utilization_rates(%)': {'max': 0, 'ave': 0.0}, 'power_usage(W)': {'max': 98.0, 'ave': 98.0}}
2025-05-19 11:42:34,703 Finished running Perf using BenchmarkTest
2025-05-19 11:43:51,411 Save logging info to ./outputs/logs
2025-05-19 11:43:51,412 config file: {'PerfRequirement': {'TTFT': 3000, 'TPOT': 100}, 'OutputHWUsage': True, 'Model': {'model_name': 'DeepSeek-R1-Distill-Qwen-7B', 'model_path': '/root/.cache/modelscope/hub/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B', 'tokenizer_path': '/root/.cache/modelscope/hub/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B'}, 'Dataset': {'use_random': False, 'data_name': 'ceval_gen', 'data_path': '/data/jason2.li/gitlab/llm_eval_toolkit/datasets/ceval'}, 'Device': 'gcu', 'DeployParam': {'batch_size': 1, 'max_batch_size': 10, 'tensor_parallel_size': 1, 'pipeline_parallel_size': 1, 'expert_parallel_size': 1, 'gpu_memory_utilization': 0.78, 'trust_remote_code': True, 'block_size': 64, 'enable_chunked_prefill': True, 'enable_prefix_caching': False, 'disable_async_output_proc': True, 'enforce_eager': False, 'distributed_executor_backend': None, 'max_num_seqs': 256, 'enable_thinking': True}, 'ModelKwargs': {'dtype': 'bfloat16', 'max_model_len': 8192, 'quantization': None}, 'SamplingParams': {'num_seqs': 1, 'max_tokens': 240, 'output_len': 240, 'temperature': 0, 'top_p': 1, 'top_k': 1, 'ignore_eos': True, 'keep_special_tokens': True, 'strict_in_out_len': True}, 'Logging': {'save_dir': './outputs/logs'}, 'MetricType': 'Perf', 'EvalTool': 'BenchmarkTest', 'InferType': 'offline', 'Acc': {'OpenCompass': {'datasets': 'ceval_gen'}, 'BenchmarkTest': {'disable-log-stats': True}, 'lm_eval': {'model': 'local-completions', 'tasks': 'ceval-valid', 'num_fewshot': 0, 'seed': 0, 'verbosity': 'DEBUG', 'log_samples': True, 'show_config': True, 'apply_chat_template': True, 'base_url': 'http://0.0.0.0:8000/v1/completions', 'num_concurrent': 1}, 'EvalScope': {'url': 'http://0.0.0.0:8000/v1/completions', 'eval_type': 'service', 'datasets': 'ceval', 'limit': 10}}, 'Perf': {'BenchmarkServing': {'input_len': 512, 'dataset_name': 'random', 'dataset_path': None, 'request_rate': 'inf', 'host': '0.0.0.0', 'port': 8000, 'endpoint': '/v1/completions', 'max_concurrency': None}, 'EvalScope': {'max_prompt_length': 5120, 'min_prompt_length': 128, 'url': 'http://0.0.0.0:8000/v1/completions', 'api': 'openai', 'dataset': 'random', 'parallel': 1, 'number': 15, 'read_timeout': 600, 'connect_timeout': 600, 'stream': True}, 'BenchmarkTest': {'input_len': 512}}, 'PerfTunning': {'BenchmarkTest': {'max_num_prompts': 100, 'min_num_prompts': 1, 'grid_num_prompts': 10}, 'BenchMarkServing': {'min_request_rate': 0.1, 'max_request_rate': 10, 'grid_request_rate': 1, 'min_num_prompts': 1, 'max_num_prompts': 100, 'grid_num_prompts': 10}}}
2025-05-19 11:43:51,412 MetricType: Perf
2025-05-19 11:43:51,412 EvalTool: BenchmarkTest
2025-05-19 11:43:51,412 InferType: offline
2025-05-19 11:43:51,412 Run command: python3 -m vllm_utils.benchmark_test --perf --model /root/.cache/modelscope/hub/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B  --tensor-parallel-size 1 --max-model-len 8192                         --input-len 512 --output-len 240 --dtype=bfloat16 --device gcu --num-prompts 1 --block-size=64 --trust-remote_code --enable-chunked-prefill --disable-async-output-proc 
2025-05-19 11:44:04,093 GCU info: {'name': b'Enflame S60', 'total_memory(MB)': 49120.0, 'utilization_rates(%)': {'max': 0, 'ave': 0.0}, 'power_usage(W)': {'max': 129.0, 'ave': 120.65079365079364}}
2025-05-19 11:44:04,093 Finished running Perf using BenchmarkTest
2025-05-19 11:44:59,143 Save logging info to ./outputs/logs
2025-05-19 11:44:59,143 config file: {'PerfRequirement': {'TTFT': 3000, 'TPOT': 100}, 'OutputHWUsage': True, 'Model': {'model_name': 'DeepSeek-R1-Distill-Qwen-7B', 'model_path': '/root/.cache/modelscope/hub/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B', 'tokenizer_path': '/root/.cache/modelscope/hub/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B'}, 'Dataset': {'use_random': False, 'data_name': 'ceval_gen', 'data_path': '/data/jason2.li/gitlab/llm_eval_toolkit/datasets/ceval'}, 'Device': 'gcu', 'DeployParam': {'batch_size': 1, 'max_batch_size': 10, 'tensor_parallel_size': 1, 'pipeline_parallel_size': 1, 'expert_parallel_size': 1, 'gpu_memory_utilization': 0.78, 'trust_remote_code': True, 'block_size': 64, 'enable_chunked_prefill': True, 'enable_prefix_caching': False, 'disable_async_output_proc': True, 'enforce_eager': False, 'distributed_executor_backend': None, 'max_num_seqs': 256, 'enable_thinking': True}, 'ModelKwargs': {'dtype': 'bfloat16', 'max_model_len': 8192, 'quantization': None}, 'SamplingParams': {'num_seqs': 1, 'max_tokens': 240, 'output_len': 240, 'temperature': 0, 'top_p': 1, 'top_k': 1, 'ignore_eos': True, 'keep_special_tokens': True, 'strict_in_out_len': True}, 'Logging': {'save_dir': './outputs/logs'}, 'MetricType': 'Perf', 'EvalTool': 'BenchmarkTest', 'InferType': 'offline', 'Acc': {'OpenCompass': {'datasets': 'ceval_gen'}, 'BenchmarkTest': {'disable-log-stats': True}, 'lm_eval': {'model': 'local-completions', 'tasks': 'ceval-valid', 'num_fewshot': 0, 'seed': 0, 'verbosity': 'DEBUG', 'log_samples': True, 'show_config': True, 'apply_chat_template': True, 'base_url': 'http://0.0.0.0:8000/v1/completions', 'num_concurrent': 1}, 'EvalScope': {'url': 'http://0.0.0.0:8000/v1/completions', 'eval_type': 'service', 'datasets': 'ceval', 'limit': 10}}, 'Perf': {'BenchmarkServing': {'input_len': 512, 'dataset_name': 'random', 'dataset_path': None, 'request_rate': 'inf', 'host': '0.0.0.0', 'port': 8000, 'endpoint': '/v1/completions', 'max_concurrency': None}, 'EvalScope': {'max_prompt_length': 5120, 'min_prompt_length': 128, 'url': 'http://0.0.0.0:8000/v1/completions', 'api': 'openai', 'dataset': 'random', 'parallel': 1, 'number': 15, 'read_timeout': 600, 'connect_timeout': 600, 'stream': True}, 'BenchmarkTest': {'input_len': 512}}, 'PerfTunning': {'BenchmarkTest': {'max_num_prompts': 100, 'min_num_prompts': 1, 'grid_num_prompts': 10}, 'BenchMarkServing': {'min_request_rate': 0.1, 'max_request_rate': 10, 'grid_request_rate': 1, 'min_num_prompts': 1, 'max_num_prompts': 100, 'grid_num_prompts': 10}}}
2025-05-19 11:44:59,144 MetricType: Perf
2025-05-19 11:44:59,144 EvalTool: BenchmarkTest
2025-05-19 11:44:59,144 InferType: offline
2025-05-19 11:44:59,144 Run command: python3 -m vllm_utils.benchmark_test --perf --model /root/.cache/modelscope/hub/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B  --tensor-parallel-size 1 --max-model-len 8192                         --input-len 512 --output-len 240 --dtype=bfloat16 --device gcu --num-prompts 1 --block-size=64 --trust-remote_code --enable-chunked-prefill --disable-async-output-proc 
2025-05-19 11:45:45,194 GCU info: {'name': b'Enflame S60', 'total_memory(MB)': 49120.0, 'utilization_rates(%)': {'max': 0, 'ave': 0.0}, 'power_usage(W)': {'max': 244.0, 'ave': 143.63469675599436}}
2025-05-19 11:45:45,194 Finished running Perf using BenchmarkTest
2025-05-19 12:15:41,895 Save logging info to ./outputs/logs
2025-05-19 12:15:41,895 config file: {'PerfRequirement': {'TTFT': 3000, 'TPOT': 100}, 'OutputHWUsage': True, 'Model': {'model_name': 'DeepSeek-R1-Distill-Qwen-7B', 'model_path': '/root/.cache/modelscope/hub/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B', 'tokenizer_path': '/root/.cache/modelscope/hub/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B'}, 'Dataset': {'use_random': False, 'data_name': 'ceval_gen', 'data_path': '/data/jason2.li/gitlab/llm_eval_toolkit/datasets/ceval'}, 'Device': 'gcu', 'DeployParam': {'batch_size': 1, 'max_batch_size': 10, 'tensor_parallel_size': 1, 'pipeline_parallel_size': 1, 'expert_parallel_size': 1, 'gpu_memory_utilization': 0.78, 'trust_remote_code': True, 'block_size': 64, 'enable_chunked_prefill': True, 'enable_prefix_caching': False, 'disable_async_output_proc': True, 'enforce_eager': False, 'distributed_executor_backend': None, 'max_num_seqs': 256, 'enable_thinking': True}, 'ModelKwargs': {'dtype': 'bfloat16', 'max_model_len': 8192, 'quantization': None}, 'SamplingParams': {'num_seqs': 1, 'max_tokens': 240, 'output_len': 240, 'temperature': 0, 'top_p': 1, 'top_k': 1, 'ignore_eos': True, 'keep_special_tokens': True, 'strict_in_out_len': True}, 'Logging': {'save_dir': './outputs/logs'}, 'MetricType': 'Perf', 'EvalTool': 'BenchmarkTest', 'InferType': 'offline', 'Acc': {'OpenCompass': {'datasets': 'ceval_gen'}, 'BenchmarkTest': {'disable-log-stats': True}, 'lm_eval': {'model': 'local-completions', 'tasks': 'ceval-valid', 'num_fewshot': 0, 'seed': 0, 'verbosity': 'DEBUG', 'log_samples': True, 'show_config': True, 'apply_chat_template': True, 'base_url': 'http://0.0.0.0:8000/v1/completions', 'num_concurrent': 1}, 'EvalScope': {'url': 'http://0.0.0.0:8000/v1/completions', 'eval_type': 'service', 'datasets': 'ceval', 'limit': 10}}, 'Perf': {'BenchmarkServing': {'input_len': 512, 'dataset_name': 'random', 'dataset_path': None, 'request_rate': 'inf', 'host': '0.0.0.0', 'port': 8000, 'endpoint': '/v1/completions', 'max_concurrency': None}, 'EvalScope': {'max_prompt_length': 5120, 'min_prompt_length': 128, 'url': 'http://0.0.0.0:8000/v1/completions', 'api': 'openai', 'dataset': 'random', 'parallel': 1, 'number': 15, 'read_timeout': 600, 'connect_timeout': 600, 'stream': True}, 'BenchmarkTest': {'input_len': 512}}, 'PerfTunning': {'BenchmarkTest': {'max_num_prompts': 100, 'min_num_prompts': 1, 'grid_num_prompts': 10}, 'BenchMarkServing': {'min_request_rate': 0.1, 'max_request_rate': 10, 'grid_request_rate': 1, 'min_num_prompts': 1, 'max_num_prompts': 100, 'grid_num_prompts': 10}}}
2025-05-19 12:15:41,895 MetricType: Perf
2025-05-19 12:15:41,895 EvalTool: BenchmarkTest
2025-05-19 12:15:41,895 InferType: offline
2025-05-19 12:15:41,895 Run command: python3 -m vllm_utils.benchmark_test --perf --model /root/.cache/modelscope/hub/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B  --tensor-parallel-size 1 --max-model-len 8192                         --input-len 512 --output-len 240 --dtype=bfloat16 --device gcu --num-prompts 1 --block-size=64 --trust-remote_code --enable-chunked-prefill --disable-async-output-proc 
2025-05-19 12:16:24,426 GCU info: {'name': b'Enflame S60', 'total_memory(MB)': 49120.0, 'utilization_rates(%)': {'max': 0, 'ave': 0.0}, 'power_usage(W)': {'max': 246.0, 'ave': 144.47013782542112}}
2025-05-19 12:16:24,430 Finished running Perf using BenchmarkTest
2025-05-19 14:37:41,067 Save logging info to ./outputs/logs
2025-05-19 14:37:41,067 config file: {'PerfRequirement': {'TTFT': 3000, 'TPOT': 100}, 'OutputHWUsage': True, 'Model': {'model_name': 'DeepSeek-R1-Distill-Qwen-7B', 'model_path': '/root/.cache/modelscope/hub/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B', 'tokenizer_path': '/root/.cache/modelscope/hub/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B'}, 'Dataset': {'use_random': False, 'data_name': 'ceval_gen', 'data_path': '/data/jason2.li/gitlab/llm_eval_toolkit/datasets/ceval'}, 'Device': 'gcu', 'DeployParam': {'batch_size': 1, 'max_batch_size': 10, 'tensor_parallel_size': 1, 'pipeline_parallel_size': 1, 'expert_parallel_size': 1, 'gpu_memory_utilization': 0.78, 'trust_remote_code': True, 'block_size': 64, 'enable_chunked_prefill': True, 'enable_prefix_caching': False, 'disable_async_output_proc': True, 'enforce_eager': False, 'distributed_executor_backend': None, 'max_num_seqs': 256, 'enable_thinking': True}, 'ModelKwargs': {'dtype': 'bfloat16', 'max_model_len': 8192, 'quantization': None}, 'SamplingParams': {'num_seqs': 1, 'max_tokens': 240, 'output_len': 240, 'temperature': 0, 'top_p': 1, 'top_k': 1, 'ignore_eos': True, 'keep_special_tokens': True, 'strict_in_out_len': True}, 'Logging': {'save_dir': './outputs/logs'}, 'MetricType': 'PerfAnalysis', 'EvalTool': 'BenchmarkTest', 'InferType': 'offline', 'Acc': {'OpenCompass': {'datasets': 'ceval_gen'}, 'BenchmarkTest': {'disable-log-stats': True}, 'lm_eval': {'model': 'local-completions', 'tasks': 'ceval-valid', 'num_fewshot': 0, 'seed': 0, 'verbosity': 'DEBUG', 'log_samples': True, 'show_config': True, 'apply_chat_template': True, 'base_url': 'http://0.0.0.0:8000/v1/completions', 'num_concurrent': 1}, 'EvalScope': {'url': 'http://0.0.0.0:8000/v1/completions', 'eval_type': 'service', 'datasets': 'ceval', 'limit': 10}}, 'Perf': {'BenchmarkServing': {'input_len': 512, 'dataset_name': 'random', 'dataset_path': None, 'request_rate': 'inf', 'host': '0.0.0.0', 'port': 8000, 'endpoint': '/v1/completions', 'max_concurrency': None}, 'EvalScope': {'max_prompt_length': 5120, 'min_prompt_length': 128, 'url': 'http://0.0.0.0:8000/v1/completions', 'api': 'openai', 'dataset': 'random', 'parallel': 1, 'number': 15, 'read_timeout': 600, 'connect_timeout': 600, 'stream': True}, 'BenchmarkTest': {'input_len': 512}}, 'PerfTunning': {'BenchmarkTest': {'max_num_prompts': 100, 'min_num_prompts': 1, 'grid_num_prompts': 10}, 'BenchMarkServing': {'min_request_rate': 0.1, 'max_request_rate': 10, 'grid_request_rate': 1, 'min_num_prompts': 1, 'max_num_prompts': 100, 'grid_num_prompts': 10}}}
2025-05-19 14:37:41,067 MetricType: PerfAnalysis
2025-05-19 14:37:41,067 EvalTool: BenchmarkTest
2025-05-19 14:37:41,067 InferType: offline
2025-05-19 14:38:01,653 Save logging info to ./outputs/logs
2025-05-19 14:38:01,653 config file: {'PerfRequirement': {'TTFT': 3000, 'TPOT': 100}, 'OutputHWUsage': True, 'Model': {'model_name': 'DeepSeek-R1-Distill-Qwen-7B', 'model_path': '/root/.cache/modelscope/hub/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B', 'tokenizer_path': '/root/.cache/modelscope/hub/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B'}, 'Dataset': {'use_random': False, 'data_name': 'ceval_gen', 'data_path': '/data/jason2.li/gitlab/llm_eval_toolkit/datasets/ceval'}, 'Device': 'gcu', 'DeployParam': {'batch_size': 1, 'max_batch_size': 10, 'tensor_parallel_size': 1, 'pipeline_parallel_size': 1, 'expert_parallel_size': 1, 'gpu_memory_utilization': 0.78, 'trust_remote_code': True, 'block_size': 64, 'enable_chunked_prefill': True, 'enable_prefix_caching': False, 'disable_async_output_proc': True, 'enforce_eager': False, 'distributed_executor_backend': None, 'max_num_seqs': 256, 'enable_thinking': True}, 'ModelKwargs': {'dtype': 'bfloat16', 'max_model_len': 8192, 'quantization': None}, 'SamplingParams': {'num_seqs': 1, 'max_tokens': 240, 'output_len': 240, 'temperature': 0, 'top_p': 1, 'top_k': 1, 'ignore_eos': True, 'keep_special_tokens': True, 'strict_in_out_len': True}, 'Logging': {'save_dir': './outputs/logs'}, 'MetricType': 'PerfAnalysis', 'EvalTool': 'BenchmarkTest', 'InferType': 'offline', 'Acc': {'OpenCompass': {'datasets': 'ceval_gen'}, 'BenchmarkTest': {'disable-log-stats': True}, 'lm_eval': {'model': 'local-completions', 'tasks': 'ceval-valid', 'num_fewshot': 0, 'seed': 0, 'verbosity': 'DEBUG', 'log_samples': True, 'show_config': True, 'apply_chat_template': True, 'base_url': 'http://0.0.0.0:8000/v1/completions', 'num_concurrent': 1}, 'EvalScope': {'url': 'http://0.0.0.0:8000/v1/completions', 'eval_type': 'service', 'datasets': 'ceval', 'limit': 10}}, 'Perf': {'BenchmarkServing': {'input_len': 512, 'dataset_name': 'random', 'dataset_path': None, 'request_rate': 'inf', 'host': '0.0.0.0', 'port': 8000, 'endpoint': '/v1/completions', 'max_concurrency': None}, 'EvalScope': {'max_prompt_length': 5120, 'min_prompt_length': 128, 'url': 'http://0.0.0.0:8000/v1/completions', 'api': 'openai', 'dataset': 'random', 'parallel': 1, 'number': 15, 'read_timeout': 600, 'connect_timeout': 600, 'stream': True}, 'BenchmarkTest': {'input_len': 512}}, 'PerfTunning': {'BenchmarkTest': {'max_num_prompts': 100, 'min_num_prompts': 1, 'grid_num_prompts': 10}, 'BenchMarkServing': {'min_request_rate': 0.1, 'max_request_rate': 10, 'grid_request_rate': 1, 'min_num_prompts': 1, 'max_num_prompts': 100, 'grid_num_prompts': 10}}}
2025-05-19 14:38:01,653 MetricType: PerfAnalysis
2025-05-19 14:38:01,653 EvalTool: BenchmarkTest
2025-05-19 14:38:01,653 InferType: offline
2025-05-19 14:38:57,165 GCU info: {'name': b'Enflame S60', 'total_memory(MB)': 49120.0, 'utilization_rates(%)': {'max': 0, 'ave': 0.0}, 'power_usage(W)': {'max': 244.0, 'ave': 140.85093896713616}}
2025-05-19 14:38:57,169 Finished running PerfAnalysis using BenchmarkTest
2025-05-19 14:45:03,426 Save logging info to ./outputs/logs
2025-05-19 14:45:03,427 config file: {'PerfRequirement': {'TTFT': 3000, 'TPOT': 100}, 'OutputHWUsage': True, 'Model': {'model_name': 'DeepSeek-R1-Distill-Qwen-7B', 'model_path': '/root/.cache/modelscope/hub/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B', 'tokenizer_path': '/root/.cache/modelscope/hub/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B'}, 'Dataset': {'use_random': False, 'data_name': 'ceval_gen', 'data_path': '/data/jason2.li/gitlab/llm_eval_toolkit/datasets/ceval'}, 'Device': 'gcu', 'DeployParam': {'batch_size': 1, 'max_batch_size': 10, 'tensor_parallel_size': 1, 'pipeline_parallel_size': 1, 'expert_parallel_size': 1, 'gpu_memory_utilization': 0.78, 'trust_remote_code': True, 'block_size': 64, 'enable_chunked_prefill': True, 'enable_prefix_caching': False, 'disable_async_output_proc': True, 'enforce_eager': False, 'distributed_executor_backend': None, 'max_num_seqs': 256, 'enable_thinking': True}, 'ModelKwargs': {'dtype': 'bfloat16', 'max_model_len': 8192, 'quantization': None}, 'SamplingParams': {'num_seqs': 1, 'max_tokens': 240, 'output_len': 240, 'temperature': 0, 'top_p': 1, 'top_k': 1, 'ignore_eos': True, 'keep_special_tokens': True, 'strict_in_out_len': True}, 'Logging': {'save_dir': './outputs/logs'}, 'MetricType': 'PerfAnalysis', 'EvalTool': 'BenchmarkTest', 'InferType': 'offline', 'Acc': {'OpenCompass': {'datasets': 'ceval_gen'}, 'BenchmarkTest': {'disable-log-stats': True}, 'lm_eval': {'model': 'local-completions', 'tasks': 'ceval-valid', 'num_fewshot': 0, 'seed': 0, 'verbosity': 'DEBUG', 'log_samples': True, 'show_config': True, 'apply_chat_template': True, 'base_url': 'http://0.0.0.0:8000/v1/completions', 'num_concurrent': 1}, 'EvalScope': {'url': 'http://0.0.0.0:8000/v1/completions', 'eval_type': 'service', 'datasets': 'ceval', 'limit': 10}}, 'Perf': {'BenchmarkServing': {'input_len': 512, 'dataset_name': 'random', 'dataset_path': None, 'request_rate': 'inf', 'host': '0.0.0.0', 'port': 8000, 'endpoint': '/v1/completions', 'max_concurrency': None}, 'EvalScope': {'max_prompt_length': 5120, 'min_prompt_length': 128, 'url': 'http://0.0.0.0:8000/v1/completions', 'api': 'openai', 'dataset': 'random', 'parallel': 1, 'number': 15, 'read_timeout': 600, 'connect_timeout': 600, 'stream': True}, 'BenchmarkTest': {'input_len': 512}}, 'PerfTunning': {'BenchmarkTest': {'max_num_prompts': 100, 'min_num_prompts': 1, 'grid_num_prompts': 10}, 'BenchMarkServing': {'min_request_rate': 0.1, 'max_request_rate': 10, 'grid_request_rate': 1, 'min_num_prompts': 1, 'max_num_prompts': 100, 'grid_num_prompts': 10}}}
2025-05-19 14:45:03,427 MetricType: PerfAnalysis
2025-05-19 14:45:03,427 EvalTool: BenchmarkTest
2025-05-19 14:45:03,427 InferType: offline
2025-05-19 14:45:03,693 GCU info: {'name': b'Enflame S60', 'total_memory(MB)': 49120.0, 'utilization_rates(%)': {'max': 0, 'ave': 0.0}, 'power_usage(W)': {'max': 99.0, 'ave': 98.33333333333333}}
2025-05-19 14:45:03,693 Finished running PerfAnalysis using BenchmarkTest
2025-05-19 14:45:49,998 Save logging info to ./outputs/logs
2025-05-19 14:45:49,999 config file: {'PerfRequirement': {'TTFT': 3000, 'TPOT': 100}, 'OutputHWUsage': True, 'Model': {'model_name': 'DeepSeek-R1-Distill-Qwen-7B', 'model_path': '/root/.cache/modelscope/hub/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B', 'tokenizer_path': '/root/.cache/modelscope/hub/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B'}, 'Dataset': {'use_random': False, 'data_name': 'ceval_gen', 'data_path': '/data/jason2.li/gitlab/llm_eval_toolkit/datasets/ceval'}, 'Device': 'gcu', 'DeployParam': {'batch_size': 1, 'max_batch_size': 10, 'tensor_parallel_size': 1, 'pipeline_parallel_size': 1, 'expert_parallel_size': 1, 'gpu_memory_utilization': 0.78, 'trust_remote_code': True, 'block_size': 64, 'enable_chunked_prefill': True, 'enable_prefix_caching': False, 'disable_async_output_proc': True, 'enforce_eager': False, 'distributed_executor_backend': None, 'max_num_seqs': 256, 'enable_thinking': True}, 'ModelKwargs': {'dtype': 'bfloat16', 'max_model_len': 8192, 'quantization': None}, 'SamplingParams': {'num_seqs': 1, 'max_tokens': 240, 'output_len': 240, 'temperature': 0, 'top_p': 1, 'top_k': 1, 'ignore_eos': True, 'keep_special_tokens': True, 'strict_in_out_len': True}, 'Logging': {'save_dir': './outputs/logs'}, 'MetricType': 'PerfAnalysis', 'EvalTool': 'BenchmarkTest', 'InferType': 'offline', 'Acc': {'OpenCompass': {'datasets': 'ceval_gen'}, 'BenchmarkTest': {'disable-log-stats': True}, 'lm_eval': {'model': 'local-completions', 'tasks': 'ceval-valid', 'num_fewshot': 0, 'seed': 0, 'verbosity': 'DEBUG', 'log_samples': True, 'show_config': True, 'apply_chat_template': True, 'base_url': 'http://0.0.0.0:8000/v1/completions', 'num_concurrent': 1}, 'EvalScope': {'url': 'http://0.0.0.0:8000/v1/completions', 'eval_type': 'service', 'datasets': 'ceval', 'limit': 10}}, 'Perf': {'BenchmarkServing': {'input_len': 512, 'dataset_name': 'random', 'dataset_path': None, 'request_rate': 'inf', 'host': '0.0.0.0', 'port': 8000, 'endpoint': '/v1/completions', 'max_concurrency': None}, 'EvalScope': {'max_prompt_length': 5120, 'min_prompt_length': 128, 'url': 'http://0.0.0.0:8000/v1/completions', 'api': 'openai', 'dataset': 'random', 'parallel': 1, 'number': 15, 'read_timeout': 600, 'connect_timeout': 600, 'stream': True}, 'BenchmarkTest': {'input_len': 512}}, 'PerfTunning': {'BenchmarkTest': {'max_num_prompts': 100, 'min_num_prompts': 1, 'grid_num_prompts': 10}, 'BenchMarkServing': {'min_request_rate': 0.1, 'max_request_rate': 10, 'grid_request_rate': 1, 'min_num_prompts': 1, 'max_num_prompts': 100, 'grid_num_prompts': 10}}}
2025-05-19 14:45:49,999 MetricType: PerfAnalysis
2025-05-19 14:45:49,999 EvalTool: BenchmarkTest
2025-05-19 14:45:49,999 InferType: offline
2025-05-19 14:45:50,000 run cmd topsprof --enable-activities operator --export-visual-profiler ./output_perf_analysis --export-rawdata                 ./output_perf_analysis/MODEL.rawdata --trace all --topstx-domain-include all python3 -m vllm_utils.benchmark_test                 --perf --model /root/.cache/modelscope/hub/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B  --tensor-parallel-size 1 --max-model-len 8192                 --input-len 512 --output-len 240 --dtype=bfloat16 --device gcu --num-prompts 1 --block-size=64 --trust-remote_code --enable-chunked-prefill --disable-async-output-proc 
2025-05-19 14:45:50,267 GCU info: {'name': b'Enflame S60', 'total_memory(MB)': 49120.0, 'utilization_rates(%)': {'max': 0, 'ave': 0.0}, 'power_usage(W)': {'max': 98.0, 'ave': 98.0}}
2025-05-19 14:45:50,267 Finished running PerfAnalysis using BenchmarkTest
2025-05-19 14:46:10,212 Save logging info to ./outputs/logs
2025-05-19 14:46:10,212 config file: {'PerfRequirement': {'TTFT': 3000, 'TPOT': 100}, 'OutputHWUsage': True, 'Model': {'model_name': 'DeepSeek-R1-Distill-Qwen-7B', 'model_path': '/root/.cache/modelscope/hub/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B', 'tokenizer_path': '/root/.cache/modelscope/hub/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B'}, 'Dataset': {'use_random': False, 'data_name': 'ceval_gen', 'data_path': '/data/jason2.li/gitlab/llm_eval_toolkit/datasets/ceval'}, 'Device': 'gcu', 'DeployParam': {'batch_size': 1, 'max_batch_size': 10, 'tensor_parallel_size': 1, 'pipeline_parallel_size': 1, 'expert_parallel_size': 1, 'gpu_memory_utilization': 0.78, 'trust_remote_code': True, 'block_size': 64, 'enable_chunked_prefill': True, 'enable_prefix_caching': False, 'disable_async_output_proc': True, 'enforce_eager': False, 'distributed_executor_backend': None, 'max_num_seqs': 256, 'enable_thinking': True}, 'ModelKwargs': {'dtype': 'bfloat16', 'max_model_len': 8192, 'quantization': None}, 'SamplingParams': {'num_seqs': 1, 'max_tokens': 240, 'output_len': 240, 'temperature': 0, 'top_p': 1, 'top_k': 1, 'ignore_eos': True, 'keep_special_tokens': True, 'strict_in_out_len': True}, 'Logging': {'save_dir': './outputs/logs'}, 'MetricType': 'PerfAnalysis', 'EvalTool': 'BenchmarkTest', 'InferType': 'offline', 'Acc': {'OpenCompass': {'datasets': 'ceval_gen'}, 'BenchmarkTest': {'disable-log-stats': True}, 'lm_eval': {'model': 'local-completions', 'tasks': 'ceval-valid', 'num_fewshot': 0, 'seed': 0, 'verbosity': 'DEBUG', 'log_samples': True, 'show_config': True, 'apply_chat_template': True, 'base_url': 'http://0.0.0.0:8000/v1/completions', 'num_concurrent': 1}, 'EvalScope': {'url': 'http://0.0.0.0:8000/v1/completions', 'eval_type': 'service', 'datasets': 'ceval', 'limit': 10}}, 'Perf': {'BenchmarkServing': {'input_len': 512, 'dataset_name': 'random', 'dataset_path': None, 'request_rate': 'inf', 'host': '0.0.0.0', 'port': 8000, 'endpoint': '/v1/completions', 'max_concurrency': None}, 'EvalScope': {'max_prompt_length': 5120, 'min_prompt_length': 128, 'url': 'http://0.0.0.0:8000/v1/completions', 'api': 'openai', 'dataset': 'random', 'parallel': 1, 'number': 15, 'read_timeout': 600, 'connect_timeout': 600, 'stream': True}, 'BenchmarkTest': {'input_len': 512}}, 'PerfTunning': {'BenchmarkTest': {'max_num_prompts': 100, 'min_num_prompts': 1, 'grid_num_prompts': 10}, 'BenchMarkServing': {'min_request_rate': 0.1, 'max_request_rate': 10, 'grid_request_rate': 1, 'min_num_prompts': 1, 'max_num_prompts': 100, 'grid_num_prompts': 10}}}
2025-05-19 14:46:10,212 MetricType: PerfAnalysis
2025-05-19 14:46:10,212 EvalTool: BenchmarkTest
2025-05-19 14:46:10,212 InferType: offline
2025-05-19 14:46:10,214 run cmd topsprof --enable-activities operator --export-visual-profiler ./output_perf_analysis --export-rawdata                 ./output_perf_analysis/MODEL.rawdata --trace all --topstx-domain-include all python3 -m vllm_utils.benchmark_test                 --perf --model /root/.cache/modelscope/hub/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B  --tensor-parallel-size 1 --max-model-len 8192                 --input-len 512 --output-len 240 --dtype=bfloat16 --device gcu --num-prompts 1 --block-size=64 --trust-remote_code --enable-chunked-prefill --disable-async-output-proc 
2025-05-19 14:47:05,345 GCU info: {'name': b'Enflame S60', 'total_memory(MB)': 49120.0, 'utilization_rates(%)': {'max': 0, 'ave': 0.0}, 'power_usage(W)': {'max': 244.0, 'ave': 140.62174940898345}}
2025-05-19 14:47:05,350 Finished running PerfAnalysis using BenchmarkTest
2025-05-21 08:11:15,606 Save logging info to ./outputs/logs
2025-05-21 08:11:15,607 config file: {'PerfRequirement': {'TTFT': 3000, 'TPOT': 100}, 'OutputHWUsage': True, 'Model': {'model_name': 'DeepSeek-R1-Distill-Qwen-7B', 'model_path': '/root/.cache/modelscope/hub/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B', 'tokenizer_path': '/root/.cache/modelscope/hub/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B'}, 'Dataset': {'use_random': False, 'data_name': 'ceval_gen', 'data_path': '/data/jason2.li/gitlab/llm_eval_toolkit/datasets/ceval'}, 'Device': 'gcu', 'DeployParam': {'batch_size': 1, 'max_batch_size': 10, 'tensor_parallel_size': 1, 'pipeline_parallel_size': 1, 'expert_parallel_size': 1, 'gpu_memory_utilization': 0.78, 'trust_remote_code': True, 'block_size': 64, 'enable_chunked_prefill': True, 'enable_prefix_caching': False, 'disable_async_output_proc': True, 'enforce_eager': False, 'distributed_executor_backend': None, 'max_num_seqs': 256, 'enable_thinking': True}, 'ModelKwargs': {'dtype': 'bfloat16', 'max_model_len': 8192, 'quantization': None}, 'SamplingParams': {'num_seqs': 1, 'max_tokens': 240, 'output_len': 240, 'temperature': 0, 'top_p': 1, 'top_k': 1, 'ignore_eos': True, 'keep_special_tokens': True, 'strict_in_out_len': True}, 'Logging': {'save_dir': './outputs/logs'}, 'MetricType': 'PerfAnalysis', 'EvalTool': 'BenchmarkTest', 'InferType': 'offline', 'Acc': {'OpenCompass': {'datasets': 'ceval_gen'}, 'BenchmarkTest': {'disable-log-stats': True}, 'lm_eval': {'model': 'local-completions', 'tasks': 'ceval-valid', 'num_fewshot': 0, 'seed': 0, 'verbosity': 'DEBUG', 'log_samples': True, 'show_config': True, 'apply_chat_template': True, 'base_url': 'http://0.0.0.0:8000/v1/completions', 'num_concurrent': 1}, 'EvalScope': {'url': 'http://0.0.0.0:8000/v1/completions', 'eval_type': 'service', 'datasets': 'ceval', 'limit': 10}}, 'Perf': {'BenchmarkServing': {'input_len': 512, 'dataset_name': 'random', 'dataset_path': None, 'request_rate': 'inf', 'host': '0.0.0.0', 'port': 8000, 'endpoint': '/v1/completions', 'max_concurrency': None}, 'EvalScope': {'max_prompt_length': 5120, 'min_prompt_length': 128, 'url': 'http://0.0.0.0:8000/v1/completions', 'api': 'openai', 'dataset': 'random', 'parallel': 1, 'number': 15, 'read_timeout': 600, 'connect_timeout': 600, 'stream': True}, 'BenchmarkTest': {'input_len': 512}}, 'PerfTunning': {'BenchmarkTest': {'max_num_prompts': 100, 'min_num_prompts': 1, 'grid_num_prompts': 10}, 'BenchMarkServing': {'min_request_rate': 0.1, 'max_request_rate': 10, 'grid_request_rate': 1, 'min_num_prompts': 1, 'max_num_prompts': 100, 'grid_num_prompts': 10}}}
2025-05-21 08:11:15,607 MetricType: PerfAnalysis
2025-05-21 08:11:15,608 EvalTool: BenchmarkTest
2025-05-21 08:11:15,608 InferType: offline
2025-05-21 08:11:15,612 run cmd topsprof --enable-activities operator --export-visual-profiler ./output_perf_analysis --export-rawdata                 ./output_perf_analysis/MODEL.rawdata --trace all --topstx-domain-include all                 python3 -m vllm_utils.benchmark_test                 --perf --model /root/.cache/modelscope/hub/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B                  --tensor-parallel-size 1                 --max-model-len 8192                 --input-len 512                 --output-len 240                 --dtype=bfloat16                 --device gcu                 --num-prompts 1                 --block-size=64 --trust-remote_code --enable-chunked-prefill --disable-async-output-proc 
